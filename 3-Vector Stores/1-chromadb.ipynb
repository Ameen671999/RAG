{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "72757de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7a9cf29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## langchain imports\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "#vector store imports\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "#utility imports\n",
    "import numpy as np\n",
    "from typing import List\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a313ea29",
   "metadata": {},
   "source": [
    "\n",
    "RAG (Retrieval-Augmented Generation) Architecture:\n",
    "\n",
    "1. Document Loading: Load documents from various sources\n",
    "2. Document Splitting: Break documents into smaller chunks\n",
    "3. Embedding Generation: Convert chunks into vector representations\n",
    "4. Vector Storage: Store embeddings in ChromaDB\n",
    "5. Query Processing: Convert user query to embedding\n",
    "6. Similarity Search: Find relevant chunks from vector store\n",
    "7. Context Augmentation: Combine retrieved chunks with query\n",
    "8. Response Generation: LLM generates answer using context\n",
    "\n",
    "Benefits of RAG:\n",
    "- Reduces hallucinations\n",
    "- Provides up-to-date information\n",
    "- Allows citing sources\n",
    "- Works with domain-specific knowledge\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9d25d8",
   "metadata": {},
   "source": [
    "### 1.Sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8fbac3b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n    Machine Learning Fundamentals\\n\\n    Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through \\n    interaction with an environment using rewards and penalties.\\n    ',\n",
       " '\\n    Deep Learning and Neural Networks\\n\\n    Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language \\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers \\n    excel at sequential data processing.\\n    ',\n",
       " '\\n    Natural Language Processing (NLP)\\n\\n    NLP is a field of AI that focuses on the interaction between computers and human language. \\n    Key tasks in NLP include text classification, named entity recognition, sentiment analysis, \\n    machine translation, and question answering. Modern NLP heavily relies on transformer \\n    architectures like BERT, GPT, and T5. These models use attention mechanisms to understand \\n    context and relationships between words in text.\\n    ']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create sample documents\n",
    "sample_docs = [\n",
    "    \"\"\"\n",
    "    Machine Learning Fundamentals\n",
    "    \n",
    "    Machine learning is a subset of artificial intelligence that enables systems to learn \n",
    "    and improve from experience without being explicitly programmed. There are three main \n",
    "    types of machine learning: supervised learning, unsupervised learning, and reinforcement \n",
    "    learning. Supervised learning uses labeled data to train models, while unsupervised \n",
    "    learning finds patterns in unlabeled data. Reinforcement learning learns through \n",
    "    interaction with an environment using rewards and penalties.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"\"\"\n",
    "    Deep Learning and Neural Networks\n",
    "    \n",
    "    Deep learning is a subset of machine learning based on artificial neural networks. \n",
    "    These networks are inspired by the human brain and consist of layers of interconnected \n",
    "    nodes. Deep learning has revolutionized fields like computer vision, natural language \n",
    "    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \n",
    "    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers \n",
    "    excel at sequential data processing.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"\"\"\n",
    "    Natural Language Processing (NLP)\n",
    "    \n",
    "    NLP is a field of AI that focuses on the interaction between computers and human language. \n",
    "    Key tasks in NLP include text classification, named entity recognition, sentiment analysis, \n",
    "    machine translation, and question answering. Modern NLP heavily relies on transformer \n",
    "    architectures like BERT, GPT, and T5. These models use attention mechanisms to understand \n",
    "    context and relationships between words in text.\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "sample_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9882bba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample documents saved to C:\\Users\\ameen\\AppData\\Local\\Temp\\tmphlx_hd_z\n"
     ]
    }
   ],
   "source": [
    "## save sample documents to files\n",
    "\n",
    "import tempfile\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "\n",
    "for i,doc in enumerate(sample_docs):\n",
    "    with open(f\"{temp_dir}/doc_{i}.txt\",\"w\") as f:\n",
    "        f.write(doc)\n",
    "\n",
    "print(f\"Sample documents saved to {temp_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dee73e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample documents saved to C:\\Users\\ameen\\AppData\\Local\\Temp\\tmpgq955a25\n"
     ]
    }
   ],
   "source": [
    "## save sample documents to files\n",
    "\n",
    "import tempfile\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "\n",
    "for i,doc in enumerate(sample_docs):\n",
    "    with open(f\"doc_{i}.txt\",\"w\") as f:\n",
    "        f.write(doc)\n",
    "\n",
    "print(f\"Sample documents saved to {temp_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09df22d",
   "metadata": {},
   "source": [
    "### 2. Document Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e1022982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3 documents.\n",
      "page_content='\n",
      "    Machine Learning Fundamentals\n",
      "\n",
      "    Machine learning is a subset of artificial intelligence that enables systems to learn \n",
      "    and improve from experience without being explicitly programmed. There are three main \n",
      "    types of machine learning: supervised learning, unsupervised learning, and reinforcement \n",
      "    learning. Supervised learning uses labeled data to train models, while unsupervised \n",
      "    learning finds patterns in unlabeled data. Reinforcement learning learns through \n",
      "    interaction with an environment using rewards and penalties.\n",
      "    ' metadata={'source': 'data\\\\doc_0.txt'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "\n",
    "loader = DirectoryLoader(\n",
    "    \"data\",\n",
    "    glob=\"*.txt\",\n",
    "    loader_cls=TextLoader,\n",
    "    loader_kwargs={'encoding':'utf-8'}\n",
    ")\n",
    "\n",
    "documents = loader.load()\n",
    "print(f\"Loaded {len(documents)} documents.\")\n",
    "print(documents[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de1fb79",
   "metadata": {},
   "source": [
    "### Document Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "90e61c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split into 7 chunks.\n",
      "page_content='Machine Learning Fundamentals' metadata={'source': 'data\\\\doc_0.txt'}\n",
      "Content: Machine Learning Fundamentals\n",
      "Metadata: {'source': 'data\\\\doc_0.txt'}\n"
     ]
    }
   ],
   "source": [
    "#Intialize text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50,\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "#split documents into chunks\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"Split into {len(chunks)} chunks.\")\n",
    "print(chunks[0])\n",
    "print(\"Content:\", chunks[0].page_content)\n",
    "print(\"Metadata:\", chunks[0].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17781a6",
   "metadata": {},
   "source": [
    "### Embedding Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e2d7eb89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding vector length: 384\n",
      "[0.008409123867750168, -0.0036057783290743828, 0.055221520364284515, 0.06061022728681564, 0.031035931780934334, -0.024386070668697357, -0.02974015846848488, -0.03058423474431038, -0.07072210311889648, -0.002817013766616583, -0.04272116720676422, 0.011185051873326302, 0.05198781564831734, -0.09259222447872162, -0.014977377839386463, 0.03200259432196617, 0.0031231686007231474, 0.000482235656818375, -0.05831686779856682, -0.06758221983909607, 0.01739531010389328, -0.014859677292406559, -0.04645844176411629, 0.028661001473665237, -0.010227455757558346, 0.052249979227781296, 0.03158416971564293, 0.06607236713171005, 0.0186484195291996, -0.016719412058591843, 0.039973363280296326, -0.01592492125928402, 0.03211909905076027, -0.004316583275794983, -0.028114628046751022, 0.04597127065062523, -0.039442069828510284, 0.07581846415996552, 0.04164664447307587, -0.03430868312716484, -0.05462898686528206, -0.038186412304639816, 0.017335714772343636, -0.01833461783826351, 0.07909315079450607, 0.11327654868364334, -0.08285205811262131, -0.1150466799736023, -0.06205204874277115, -0.010751696303486824, -0.11352034658193588, -0.027699554339051247, -0.022556405514478683, -0.023302899673581123, -0.049555107951164246, 0.0859128087759018, 0.01777978427708149, 0.057156674563884735, -0.01265763957053423, -0.03027842566370964, 0.013175241649150848, -0.13028882443904877, -0.00620758393779397, 0.038361310958862305, 0.02443661168217659, 0.03359216824173927, -0.03384067118167877, 0.040168773382902145, 0.0020071843173354864, -0.05820159241557121, -0.0030443144496530294, 0.09242582321166992, 0.05763000622391701, 0.0409255251288414, 0.0385834164917469, -0.026200884953141212, -0.01624714769423008, -0.027523603290319443, 0.0997440293431282, 0.04923322796821594, -0.001080723712220788, 0.021503683179616928, -0.05569704994559288, 0.09585631638765335, 0.005194263532757759, -0.09079521149396896, -0.0304550901055336, -0.004329379182308912, -0.010577207431197166, 0.02047053724527359, -0.006522553972899914, -0.0746331587433815, -0.021134061738848686, -0.07196344435214996, 0.004398982971906662, 0.03296011686325073, 0.022158091887831688, -0.09398013353347778, -0.014520503580570221, 0.042805008590221405, -0.021363647654652596, 0.06917222589254379, -0.03064093180000782, 0.02017849311232567, 0.02237376943230629, -0.009149156510829926, 0.028859928250312805, 0.0007325685583055019, 0.09540945291519165, -0.13025616109371185, -0.04176334664225578, 0.042460303753614426, -0.006890235468745232, -0.0641067773103714, -0.03269432857632637, 0.014608815312385559, -0.005162533838301897, 0.02815048210322857, 0.009163297712802887, 0.08945699036121368, -0.020760618150234222, 0.010388325899839401, 0.024161072447896004, 0.05174220725893974, 0.008506612852215767, -0.11876808851957321, -0.06425037235021591, -6.7743440972525916e-34, -0.03757784143090248, -0.0894196480512619, 0.046140458434820175, -0.010893567465245724, 0.04217337816953659, -0.07144588977098465, -0.018699605017900467, -0.08852103352546692, 0.020842332392930984, 0.039210349321365356, -0.0436905100941658, 0.0020850044675171375, 0.03766992315649986, 0.1279289871454239, 0.08877653628587723, 0.0572841577231884, -0.035189855843782425, 0.05655090883374214, 0.013205115683376789, -0.04541485756635666, 0.057704586535692215, -0.026339536532759666, 0.0027023782022297382, -0.0386631041765213, -0.05727173760533333, 0.04874725267291069, 0.05535273253917694, 0.027974575757980347, 0.010579323396086693, 0.014535019174218178, 0.01657666265964508, 0.06550576537847519, -0.07290160655975342, 0.039489421993494034, 0.04216375574469566, 0.0016346052289009094, 0.016891008242964745, -0.021510688588023186, 0.057243600487709045, 0.01688680611550808, -0.011626792140305042, -0.030497130006551743, 0.059837859123945236, -0.036342356353998184, -0.042669642716646194, 0.009516256861388683, 0.034420449286699295, -0.10193927586078644, -0.024099303409457207, -0.04506248980760574, -0.032143671065568924, -0.014335730113089085, -0.023411082103848457, -0.06501587480306625, 0.02773209661245346, 0.06622838228940964, 0.01643119752407074, 0.02258490025997162, -0.010627012699842453, 0.015922660008072853, 0.05201831832528114, 0.01918531395494938, 0.04661191999912262, 0.058889154344797134, 0.01321372203528881, 0.0645333081483841, 0.060731399804353714, 0.022262124344706535, 0.06878942996263504, 0.026181550696492195, 0.024394264444708824, 0.02978256158530712, 0.035666175186634064, -0.011478884145617485, 0.037333350628614426, -0.04288415238261223, 0.040781170129776, -0.020541448146104813, -0.013405040837824345, 0.03888421505689621, -0.03450103849172592, -0.054823633283376694, -0.07773761451244354, -0.07386506348848343, 0.051604945212602615, 0.03018166497349739, -0.024824019521474838, -0.06120515242218971, -0.03295361250638962, -0.009344256483018398, -0.11083824187517166, -0.04600968211889267, -0.03709881752729416, 0.05032489821314812, -0.01632949523627758, -2.1573658639519357e-33, -0.019695714116096497, 0.0349300354719162, -0.05676005408167839, 0.10818718373775482, 0.006135984323918819, 0.01685161143541336, -0.05900895968079567, -0.006034667603671551, -0.048007041215896606, 0.020290642976760864, -0.04680577293038368, -0.0023542018607258797, 0.05615498870611191, 0.05059628188610077, -0.06288108229637146, 0.06223047524690628, -0.09968617558479309, 0.007463886868208647, -0.06660789251327515, 0.022037649527192116, -0.018365874886512756, 0.09115108102560043, -0.0028239688836038113, 0.009716798551380634, 0.023077823221683502, -0.004095457494258881, -0.09814994037151337, 0.054956600069999695, -0.032422441989183426, 0.041942156851291656, -0.054410651326179504, 0.0247504785656929, -0.057981304824352264, -0.05136089771986008, 0.017972955480217934, 0.058948226273059845, 0.07465905696153641, -0.03919824957847595, -0.05250026658177376, 0.037154100835323334, 0.006649278104305267, -0.007866756059229374, -0.11307674646377563, -0.04530208930373192, 0.01865532249212265, -0.01763436757028103, -0.03422511741518974, -0.04081426560878754, 0.04175195470452309, -0.06610455363988876, -0.026900120079517365, 0.028620753437280655, -0.006521117407828569, -0.07945794612169266, -0.048439446836709976, 0.004244109615683556, -0.02410782314836979, 0.018571646884083748, 0.07091815769672394, 0.07318819314241409, -0.051615823060274124, -0.10360462963581085, -0.0015399784315377474, 0.016322704032063484, -0.01893630065023899, 0.033296048641204834, -0.007992670871317387, 0.09592126309871674, -0.026441665366292, -0.07346120476722717, 0.00013238225074019283, 0.04563845694065094, -0.0583784356713295, 0.05701620876789093, -0.02965393103659153, -0.05329018831253052, -0.03625794127583504, -0.054830536246299744, -0.034263726323843, -0.021895281970500946, 0.061102963984012604, -0.07184075564146042, 0.03227059170603752, 0.04574915021657944, -0.015895821154117584, 0.0074494872242212296, -0.0024421324487775564, 0.01091710850596428, -0.046164967119693756, -0.08871432393789291, -0.03252528980374336, 0.02839580737054348, -0.07963979989290237, 0.056794341653585434, -0.11157845705747604, -2.9784699151491623e-08, 0.004030446521937847, -0.025811897590756416, 0.10466114431619644, -0.027075154706835747, 0.10504971444606781, 0.08325707912445068, -0.0844995379447937, 0.10096926242113113, -0.07992835342884064, -0.049511462450027466, 0.04298297315835953, -0.011255434714257717, -0.012421908788383007, 0.021457072347402573, 0.03207620605826378, 0.06875170022249222, 0.03784304857254028, -0.0003060123708564788, -0.009484285488724709, 0.03514890745282173, 0.11881829053163528, -0.007503568194806576, 0.020290492102503777, -0.04254019632935524, 0.028020543977618217, -0.09791268408298492, -0.005493129137903452, 0.018512723967432976, -0.02795313484966755, 0.040084969252347946, -0.026527825742959976, 0.03208232298493385, 0.04100100323557854, -0.005534150172024965, 0.06154169142246246, 0.13947263360023499, 0.049685288220644, -0.10123879462480545, -0.07974418252706528, -0.047464847564697266, -0.07710854709148407, 0.10047389566898346, -0.024956027045845985, 0.010141512379050255, -0.02757057175040245, 0.025238798931241035, 0.04865482077002525, -0.06948114931583405, -0.014060485176742077, 0.02177422307431698, 0.0554611012339592, 0.0532512441277504, 0.04965953901410103, 0.08653625100851059, 0.07617214322090149, -0.006916993297636509, 0.045507319271564484, -0.05244888365268707, 0.010841202922165394, 0.09088938683271408, 0.00838542077690363, 0.11629936844110489, 0.013947566039860249, -0.08236045390367508]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "sample_text = \"Machine learning is a subset of artificial intelligence that enables systems to learn and improve from experience without being explicitly programmed.\"\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name= \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "vector = embeddings.embed_query(sample_text)\n",
    "print(f\"Embedding vector length: {len(vector)}\")\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5bb31c",
   "metadata": {},
   "source": [
    "### Intialize the ChromaDB Vector Store And Stores the Cunks in Vector Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "17119423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chromadb in c:\\users\\ameen\\documents\\genai\\python\\venv\\lib\\site-packages (1.3.4)\n",
      "Requirement already satisfied: build>=1.0.3 in c:\\users\\ameen\\documents\\genai\\python\\venv\\lib\\site-packages (from chromadb) (1.3.0)\n",
      "Requirement already satisfied: pydantic>=1.9 in c:\\users\\ameen\\appdata\\roaming\\python\\python312\\site-packages (from chromadb) (2.12.4)\n",
      "Requirement already satisfied: pybase64>=1.4.1 in c:\\users\\ameen\\documents\\genai\\python\\venv\\lib\\site-packages (from chromadb) (1.4.2)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in c:\\users\\ameen\\documents\\genai\\python\\venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.38.0)\n",
      "Requirement already satisfied: numpy>=1.22.5 in c:\\users\\ameen\\appdata\\roaming\\python\\python312\\site-packages (from chromadb) (1.26.3)\n",
      "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in c:\\users\\ameen\\documents\\genai\\python\\venv\\lib\\site-packages (from chromadb) (5.4.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\ameen\\appdata\\roaming\\python\\python312\\site-packages (from chromadb) (4.15.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in c:\\users\\ameen\\documents\\genai\\python\\venv\\lib\\site-packages (from chromadb) (1.23.2)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in c:\\users\\ameen\\documents\\genai\\python\\venv\\lib\\site-packages (from chromadb) (1.38.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in c:\\users\\ameen\\documents\\genai\\python\\venv\\lib\\site-packages (from chromadb) (1.38.0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in c:\\users\\ameen\\documents\\genai\\python\\venv\\lib\\site-packages (from chromadb) (1.38.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\ameen\\appdata\\roaming\\python\\python312\\site-packages (from chromadb) (0.22.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in c:\\users\\ameen\\documents\\genai\\python\\venv\\lib\\site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\ameen\\appdata\\roaming\\python\\python312\\site-packages (from chromadb) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\ameen\\documents\\genai\\python\\venv\\lib\\site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\ameen\\documents\\genai\\python\\venv\\lib\\site-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\ameen\\documents\\genai\\python\\venv\\lib\\site-packages (from chromadb) (1.76.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in c:\\users\\ameen\\documents\\genai\\python\\venv\\lib\\site-packages (from chromadb) (5.0.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in c:\\users\\ameen\\documents\\genai\\python\\venv\\lib\\site-packages (from chromadb) (0.20.0)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in c:\\users\\ameen\\documents\\genai\\python\\venv\\lib\\site-packages (from chromadb) (34.1.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in c:\\users\\ameen\\appdata\\roaming\\python\\python312\\site-packages (from chromadb) (9.1.2)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in c:\\users\\ameen\\appdata\\roaming\\python\\python312\\site-packages (from chromadb) (6.0.3)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in c:\\users\\ameen\\documents\\genai\\python\\venv\\lib\\site-packages (from chromadb) (5.2.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\ameen\\appdata\\roaming\\python\\python312\\site-packages (from chromadb) (3.11.4)\n",
      "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\ameen\\appdata\\roaming\\python\\python312\\site-packages (from chromadb) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\ameen\\documents\\genai\\python\\venv\\lib\\site-packages (from chromadb) (14.2.0)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in c:\\users\\ameen\\documents\\genai\\python\\venv\\lib\\site-packages (from chromadb) (4.23.0)\n",
      "Requirement already satisfied: packaging>=19.1 in c:\\users\\ameen\\appdata\\roaming\\python\\python312\\site-packages (from build>=1.0.3->chromadb) (23.2)\n",
      "Requirement already satisfied: pyproject_hooks in c:\\users\\ameen\\documents\\genai\\python\\venv\\lib\\site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ameen\\appdata\\roaming\\python\\python312\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Requirement already satisfied: anyio in c:\\users\\ameen\\appdata\\roaming\\python\\python312\\site-packages (from httpx>=0.27.0->chromadb) (4.11.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\ameen\\appdata\\roaming\\python\\python312\\site-packages (from httpx>=0.27.0->chromadb) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\ameen\\appdata\\roaming\\python\\python312\\site-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\ameen\\appdata\\roaming\\python\\python312\\site-packages (from httpx>=0.27.0->chromadb) (3.6)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\ameen\\appdata\\roaming\\python\\python312\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\ameen\\appdata\\roaming\\python\\python312\\site-packages (from jsonschema>=4.19.0->chromadb) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\ameen\\documents\\genai\\python\\venv\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\ameen\\documents\\genai\\python\\venv\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\ameen\\documents\\genai\\python\\venv\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.24.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\ameen\\appdata\\roaming\\python\\python312\\site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\ameen\\appdata\\roaming\\python\\python312\\site-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in c:\\users\\ameen\\documents\\genai\\python\\venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.43.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\ameen\\documents\\genai\\python\\venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: requests in c:\\users\\ameen\\appdata\\roaming\\python\\python312\\site-packages (from kubernetes>=28.1.0->chromadb) (2.32.5)\n",
      "Requirement already satisfied: requests-oauthlib in c:\\users\\ameen\\documents\\genai\\python\\venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: urllib3<2.4.0,>=1.24.2 in c:\\users\\ameen\\appdata\\roaming\\python\\python312\\site-packages (from kubernetes>=28.1.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: durationpy>=0.7 in c:\\users\\ameen\\documents\\genai\\python\\venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (0.10)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\ameen\\documents\\genai\\python\\venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\ameen\\documents\\genai\\python\\venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (25.9.23)\n",
      "Requirement already satisfied: protobuf in c:\\users\\ameen\\documents\\genai\\python\\venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (5.29.4)\n",
      "Requirement already satisfied: sympy in c:\\users\\ameen\\appdata\\roaming\\python\\python312\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in c:\\users\\ameen\\documents\\genai\\python\\venv\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (8.6.1)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in c:\\users\\ameen\\documents\\genai\\python\\venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.72.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.38.0 in c:\\users\\ameen\\documents\\genai\\python\\venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.38.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.38.0 in c:\\users\\ameen\\documents\\genai\\python\\venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.38.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.59b0 in c:\\users\\ameen\\documents\\genai\\python\\venv\\lib\\site-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.59b0)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\ameen\\documents\\genai\\python\\venv\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in c:\\users\\ameen\\appdata\\roaming\\python\\python312\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\ameen\\appdata\\roaming\\python\\python312\\site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\ameen\\appdata\\roaming\\python\\python312\\site-packages (from pydantic>=1.9->chromadb) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\ameen\\appdata\\roaming\\python\\python312\\site-packages (from pydantic>=1.9->chromadb) (0.4.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\ameen\\documents\\genai\\python\\venv\\lib\\site-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\ameen\\appdata\\roaming\\python\\python312\\site-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in c:\\users\\ameen\\appdata\\roaming\\python\\python312\\site-packages (from tokenizers>=0.13.2->chromadb) (0.36.0)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\ameen\\appdata\\roaming\\python\\python312\\site-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\ameen\\appdata\\roaming\\python\\python312\\site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in c:\\users\\ameen\\documents\\genai\\python\\venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.7.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\ameen\\appdata\\roaming\\python\\python312\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.2.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\ameen\\documents\\genai\\python\\venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\users\\ameen\\documents\\genai\\python\\venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in c:\\users\\ameen\\documents\\genai\\python\\venv\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\ameen\\documents\\genai\\python\\venv\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\ameen\\documents\\genai\\python\\venv\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\ameen\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\ameen\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.10.0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\ameen\\documents\\genai\\python\\venv\\lib\\site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\ameen\\documents\\genai\\python\\venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\ameen\\appdata\\roaming\\python\\python312\\site-packages (from requests->kubernetes>=28.1.0->chromadb) (3.3.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\ameen\\appdata\\roaming\\python\\python312\\site-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\ameen\\documents\\genai\\python\\venv\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\ameen\\documents\\genai\\python\\venv\\lib\\site-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb) (3.3.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ameen\\appdata\\roaming\\python\\python312\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\ameen\\documents\\genai\\python\\venv\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb) (3.5.4)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\users\\ameen\\documents\\genai\\python\\venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
      "Vector collection count: 98\n",
      "Persisted at: ./chromadb_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "## Create a Chromdb vector store\n",
    "!pip install chromadb\n",
    "persist_directory = \"./chromadb_data\"\n",
    "\n",
    "## Innitialize Chromadb with huggingface embeddings\n",
    "vectorstore=Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=persist_directory,\n",
    "    collection_name=\"rag_collection\"\n",
    ")\n",
    "\n",
    "print(\"Vector collection count:\", vectorstore._collection.count())\n",
    "print(f\"Persisted at: {persist_directory}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eec2132",
   "metadata": {},
   "source": [
    "### Test Similarity Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "041457aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data\\\\doc_2.txt'}, page_content='Natural Language Processing (NLP)\\n\\n    NLP is a field of AI that focuses on the interaction between computers and human language. \\n    Key tasks in NLP include text classification, named entity recognition, sentiment analysis, \\n    machine translation, and question answering. Modern NLP heavily relies on transformer \\n    architectures like BERT, GPT, and T5. These models use attention mechanisms to understand \\n    context and relationships between words in text.'),\n",
       " Document(metadata={'source': 'data\\\\doc_2.txt'}, page_content='Natural Language Processing (NLP)\\n\\n    NLP is a field of AI that focuses on the interaction between computers and human language. \\n    Key tasks in NLP include text classification, named entity recognition, sentiment analysis, \\n    machine translation, and question answering. Modern NLP heavily relies on transformer \\n    architectures like BERT, GPT, and T5. These models use attention mechanisms to understand \\n    context and relationships between words in text.'),\n",
       " Document(metadata={'source': 'data\\\\doc_2.txt'}, page_content='Natural Language Processing (NLP)\\n\\n    NLP is a field of AI that focuses on the interaction between computers and human language. \\n    Key tasks in NLP include text classification, named entity recognition, sentiment analysis, \\n    machine translation, and question answering. Modern NLP heavily relies on transformer \\n    architectures like BERT, GPT, and T5. These models use attention mechanisms to understand \\n    context and relationships between words in text.')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is NLP?\"\n",
    "\n",
    "similar_docs = vectorstore.similarity_search(query,k=3)\n",
    "similar_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd2b1c3",
   "metadata": {},
   "source": [
    "### QAdvanced Similarity Search With Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e15101b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(metadata={'source': 'data\\\\doc_2.txt'}, page_content='Natural Language Processing (NLP)\\n\\n    NLP is a field of AI that focuses on the interaction between computers and human language. \\n    Key tasks in NLP include text classification, named entity recognition, sentiment analysis, \\n    machine translation, and question answering. Modern NLP heavily relies on transformer \\n    architectures like BERT, GPT, and T5. These models use attention mechanisms to understand \\n    context and relationships between words in text.'),\n",
       "  0.6382690668106079),\n",
       " (Document(metadata={'source': 'data\\\\doc_2.txt'}, page_content='Natural Language Processing (NLP)\\n\\n    NLP is a field of AI that focuses on the interaction between computers and human language. \\n    Key tasks in NLP include text classification, named entity recognition, sentiment analysis, \\n    machine translation, and question answering. Modern NLP heavily relies on transformer \\n    architectures like BERT, GPT, and T5. These models use attention mechanisms to understand \\n    context and relationships between words in text.'),\n",
       "  0.6382690668106079),\n",
       " (Document(metadata={'source': 'data\\\\doc_2.txt'}, page_content='Natural Language Processing (NLP)\\n\\n    NLP is a field of AI that focuses on the interaction between computers and human language. \\n    Key tasks in NLP include text classification, named entity recognition, sentiment analysis, \\n    machine translation, and question answering. Modern NLP heavily relies on transformer \\n    architectures like BERT, GPT, and T5. These models use attention mechanisms to understand \\n    context and relationships between words in text.'),\n",
       "  0.6382690668106079)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_scores = vectorstore.similarity_search_with_score(query,k=3)\n",
    "results_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2efcbb",
   "metadata": {},
   "source": [
    "#### Understanding Similarity Scores\n",
    "The similarity score represents how closely related a document chunk is to your query. The scoring depends on the distance metric used:\n",
    "\n",
    "ChromaDB default: Uses L2 distance (Euclidean distance)\n",
    "\n",
    "- Lower scores = MORE similar (closer in vector space)\n",
    "- Score of 0 = identical vectors\n",
    "- Typical range: 0 to 2 (but can be higher)\n",
    "\n",
    "\n",
    "Cosine similarity (if configured):\n",
    "\n",
    "- Higher scores = MORE similar\n",
    "- Range: -1 to 1 (1 being identical)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a69c5e",
   "metadata": {},
   "source": [
    "### Initialize LLM, RAG Chain, Prompt Template, Query the RAG System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7a3c0d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import inspect\n",
    "\n",
    "# print(inspect.signature(HuggingFaceEmbeddings.__init__))\n",
    "\n",
    "# llm = HuggingFaceEmbeddings(\n",
    "#     model_id = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "# )\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "llm = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a30044",
   "metadata": {},
   "source": [
    "### Modern RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1664d6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from langchain_classic.chains import create_retrieval_chain\n",
    "\n",
    "from langchain_classic.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1054c98b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x000001D3628DBA40>, search_kwargs={})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Convert vector store to retriever\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_kwarg={\"k\":3}\n",
    ")\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "78fb2399",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a prompt template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "system_prompt=\"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Use three sentences maximum and keep the answer concise.\n",
    "\n",
    "Context: {context}\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "98219519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. \\nUse the following pieces of retrieved context to answer the question. \\nIf you don't know the answer, just say that you don't know. \\nUse three sentences maximum and keep the answer concise.\\n\\nContext: {context}\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "68653fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-classic in c:\\users\\ameen\\appdata\\roaming\\python\\python312\\site-packages (1.0.0)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in c:\\users\\ameen\\appdata\\roaming\\python\\python312\\site-packages (from langchain-classic) (1.0.4)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.0.0 in c:\\users\\ameen\\appdata\\roaming\\python\\python312\\site-packages (from langchain-classic) (1.0.0)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.1.17 in c:\\users\\ameen\\appdata\\roaming\\python\\python312\\site-packages (from langchain-classic) (0.4.41)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\ameen\\appdata\\roaming\\python\\python312\\site-packages (from langchain-classic) (2.12.4)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\ameen\\appdata\\roaming\\python\\python312\\site-packages (from langchain-classic) (6.0.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in c:\\users\\ameen\\appdata\\roaming\\python\\python312\\site-packages (from langchain-classic) (2.32.5)\n",
      "Requirement already satisfied: sqlalchemy<3.0.0,>=1.4.0 in c:\\users\\ameen\\appdata\\roaming\\python\\python312\\site-packages (from langchain-classic) (2.0.44)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\ameen\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-classic) (1.33)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\ameen\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-classic) (23.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\ameen\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-classic) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\ameen\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-classic) (4.15.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\ameen\\appdata\\roaming\\python\\python312\\site-packages (from langsmith<1.0.0,>=0.1.17->langchain-classic) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\ameen\\appdata\\roaming\\python\\python312\\site-packages (from langsmith<1.0.0,>=0.1.17->langchain-classic) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\ameen\\appdata\\roaming\\python\\python312\\site-packages (from langsmith<1.0.0,>=0.1.17->langchain-classic) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\ameen\\appdata\\roaming\\python\\python312\\site-packages (from langsmith<1.0.0,>=0.1.17->langchain-classic) (0.25.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\ameen\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\ameen\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\ameen\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\ameen\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0,>=2.0.0->langchain-classic) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ameen\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0,>=2.0.0->langchain-classic) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ameen\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0,>=2.0.0->langchain-classic) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ameen\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0,>=2.0.0->langchain-classic) (2024.2.2)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\ameen\\appdata\\roaming\\python\\python312\\site-packages (from sqlalchemy<3.0.0,>=1.4.0->langchain-classic) (3.2.4)\n",
      "Requirement already satisfied: anyio in c:\\users\\ameen\\appdata\\roaming\\python\\python312\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.17->langchain-classic) (4.11.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\ameen\\appdata\\roaming\\python\\python312\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.17->langchain-classic) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\ameen\\appdata\\roaming\\python\\python312\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.17->langchain-classic) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\ameen\\appdata\\roaming\\python\\python312\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain-classic) (3.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\ameen\\appdata\\roaming\\python\\python312\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.17->langchain-classic) (1.3.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableLambda(format_docs)\n",
       "}), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "| ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. \\nUse the following pieces of retrieved context to answer the question. \\nIf you don't know the answer, just say that you don't know. \\nUse three sentences maximum and keep the answer concise.\\n\\nContext: {context}\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "| RunnableLambda(...)\n",
       "| StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create document chain\n",
    "!pip install langchain-classic\n",
    "from langchain_classic.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "document_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b9422a10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableBinding(bound=RunnableLambda(lambda x: x['input'])\n",
       "           | VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x000001D3628DBA40>, search_kwargs={}), kwargs={}, config={'run_name': 'retrieve_documents'}, config_factories=[])\n",
       "})\n",
       "| RunnableAssign(mapper={\n",
       "    answer: RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "              context: RunnableLambda(format_docs)\n",
       "            }), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "            | ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. \\nUse the following pieces of retrieved context to answer the question. \\nIf you don't know the answer, just say that you don't know. \\nUse three sentences maximum and keep the answer concise.\\n\\nContext: {context}\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "            | RunnableLambda(...)\n",
       "            | StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])\n",
       "  }), kwargs={}, config={'run_name': 'retrieval_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Create the final RAG Chain\n",
    "# !pip install langchain-classic\n",
    "\n",
    "# Correct import path\n",
    "from langchain_classic.chains.retrieval import create_retrieval_chain\n",
    "\n",
    "# Fix the typo: create_retrival_chain -> create_retrieval_chain\n",
    "rag_chain = create_retrieval_chain(retriever, document_chain)\n",
    "rag_chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3a687fb8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ChatPromptValue' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m response = \u001b[43mrag_chain\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWhat is deep Learning\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_core\\runnables\\base.py:5534\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5527\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5528\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5529\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5532\u001b[39m     **kwargs: Any | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   5533\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5534\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5535\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5536\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5537\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5538\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_core\\runnables\\base.py:3129\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3127\u001b[39m                 input_ = context.run(step.invoke, input_, config, **kwargs)\n\u001b[32m   3128\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3129\u001b[39m                 input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3130\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3131\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_core\\runnables\\passthrough.py:507\u001b[39m, in \u001b[36mRunnableAssign.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    500\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    501\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    502\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    505\u001b[39m     **kwargs: Any,\n\u001b[32m    506\u001b[39m ) -> \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[32m--> \u001b[39m\u001b[32m507\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_invoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_core\\runnables\\base.py:2050\u001b[39m, in \u001b[36mRunnable._call_with_config\u001b[39m\u001b[34m(self, func, input_, config, run_type, serialized, **kwargs)\u001b[39m\n\u001b[32m   2046\u001b[39m     child_config = patch_config(config, callbacks=run_manager.get_child())\n\u001b[32m   2047\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   2048\u001b[39m         output = cast(\n\u001b[32m   2049\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mOutput\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m-> \u001b[39m\u001b[32m2050\u001b[39m             \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2051\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   2052\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2053\u001b[39m \u001b[43m                \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2054\u001b[39m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2055\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2056\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2057\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   2058\u001b[39m         )\n\u001b[32m   2059\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   2060\u001b[39m     run_manager.on_chain_error(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_core\\runnables\\config.py:428\u001b[39m, in \u001b[36mcall_func_with_variable_args\u001b[39m\u001b[34m(func, input, config, run_manager, **kwargs)\u001b[39m\n\u001b[32m    426\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[32m    427\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m] = run_manager\n\u001b[32m--> \u001b[39m\u001b[32m428\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_core\\runnables\\passthrough.py:493\u001b[39m, in \u001b[36mRunnableAssign._invoke\u001b[39m\u001b[34m(self, value, run_manager, config, **kwargs)\u001b[39m\n\u001b[32m    488\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mThe input to RunnablePassthrough.assign() must be a dict.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    489\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)  \u001b[38;5;66;03m# noqa: TRY004\u001b[39;00m\n\u001b[32m    491\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m    492\u001b[39m     **value,\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m     **\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    498\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_core\\runnables\\base.py:3854\u001b[39m, in \u001b[36mRunnableParallel.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3848\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[32m   3849\u001b[39m         futures = [\n\u001b[32m   3850\u001b[39m             executor.submit(_invoke_step, step, \u001b[38;5;28minput\u001b[39m, config, key)\n\u001b[32m   3851\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m key, step \u001b[38;5;129;01min\u001b[39;00m steps.items()\n\u001b[32m   3852\u001b[39m         ]\n\u001b[32m   3853\u001b[39m         output = {\n\u001b[32m-> \u001b[39m\u001b[32m3854\u001b[39m             key: \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3855\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m key, future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(steps, futures, strict=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   3856\u001b[39m         }\n\u001b[32m   3857\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3858\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ameen\\Documents\\GenAI\\python\\venv\\Lib\\concurrent\\futures\\_base.py:456\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    454\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    455\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    458\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ameen\\Documents\\GenAI\\python\\venv\\Lib\\concurrent\\futures\\_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ameen\\Documents\\GenAI\\python\\venv\\Lib\\concurrent\\futures\\thread.py:58\u001b[39m, in \u001b[36m_WorkItem.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     55\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     60\u001b[39m     \u001b[38;5;28mself\u001b[39m.future.set_exception(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_core\\runnables\\base.py:3837\u001b[39m, in \u001b[36mRunnableParallel.invoke.<locals>._invoke_step\u001b[39m\u001b[34m(step, input_, config, key)\u001b[39m\n\u001b[32m   3831\u001b[39m child_config = patch_config(\n\u001b[32m   3832\u001b[39m     config,\n\u001b[32m   3833\u001b[39m     \u001b[38;5;66;03m# mark each step as a child run\u001b[39;00m\n\u001b[32m   3834\u001b[39m     callbacks=run_manager.get_child(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmap:key:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m),\n\u001b[32m   3835\u001b[39m )\n\u001b[32m   3836\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m-> \u001b[39m\u001b[32m3837\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3838\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3839\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3840\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchild_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3841\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_core\\runnables\\base.py:5534\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5527\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5528\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5529\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5532\u001b[39m     **kwargs: Any | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   5533\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5534\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5535\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5536\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5537\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5538\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_core\\runnables\\base.py:3129\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3127\u001b[39m                 input_ = context.run(step.invoke, input_, config, **kwargs)\n\u001b[32m   3128\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3129\u001b[39m                 input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3130\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3131\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_core\\runnables\\base.py:4857\u001b[39m, in \u001b[36mRunnableLambda.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   4842\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Invoke this `Runnable` synchronously.\u001b[39;00m\n\u001b[32m   4843\u001b[39m \n\u001b[32m   4844\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   4854\u001b[39m \n\u001b[32m   4855\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4856\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfunc\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m4857\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4858\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_invoke\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4859\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4860\u001b[39m \u001b[43m        \u001b[49m\u001b[43mensure_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4861\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4862\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4863\u001b[39m msg = \u001b[33m\"\u001b[39m\u001b[33mCannot invoke a coroutine function synchronously.Use `ainvoke` instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4864\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_core\\runnables\\base.py:2050\u001b[39m, in \u001b[36mRunnable._call_with_config\u001b[39m\u001b[34m(self, func, input_, config, run_type, serialized, **kwargs)\u001b[39m\n\u001b[32m   2046\u001b[39m     child_config = patch_config(config, callbacks=run_manager.get_child())\n\u001b[32m   2047\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   2048\u001b[39m         output = cast(\n\u001b[32m   2049\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mOutput\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m-> \u001b[39m\u001b[32m2050\u001b[39m             \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2051\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   2052\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2053\u001b[39m \u001b[43m                \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2054\u001b[39m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2055\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2056\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2057\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   2058\u001b[39m         )\n\u001b[32m   2059\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   2060\u001b[39m     run_manager.on_chain_error(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_core\\runnables\\config.py:428\u001b[39m, in \u001b[36mcall_func_with_variable_args\u001b[39m\u001b[34m(func, input, config, run_manager, **kwargs)\u001b[39m\n\u001b[32m    426\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[32m    427\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m] = run_manager\n\u001b[32m--> \u001b[39m\u001b[32m428\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_core\\runnables\\base.py:4714\u001b[39m, in \u001b[36mRunnableLambda._invoke\u001b[39m\u001b[34m(self, input_, run_manager, config, **kwargs)\u001b[39m\n\u001b[32m   4712\u001b[39m                 output = chunk\n\u001b[32m   4713\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4714\u001b[39m     output = \u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4715\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   4716\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4717\u001b[39m \u001b[38;5;66;03m# If the output is a Runnable, invoke it\u001b[39;00m\n\u001b[32m   4718\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, Runnable):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_core\\runnables\\config.py:428\u001b[39m, in \u001b[36mcall_func_with_variable_args\u001b[39m\u001b[34m(func, input, config, run_manager, **kwargs)\u001b[39m\n\u001b[32m    426\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[32m    427\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m] = run_manager\n\u001b[32m--> \u001b[39m\u001b[32m428\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sentence_transformers\\SentenceTransformer.py:1175\u001b[39m, in \u001b[36mSentenceTransformer.forward\u001b[39m\u001b[34m(self, input, **kwargs)\u001b[39m\n\u001b[32m   1169\u001b[39m             module_kwarg_keys = \u001b[38;5;28mself\u001b[39m.module_kwargs.get(module_name, [])\n\u001b[32m   1170\u001b[39m         module_kwargs = {\n\u001b[32m   1171\u001b[39m             key: value\n\u001b[32m   1172\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m kwargs.items()\n\u001b[32m   1173\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module_kwarg_keys \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28mhasattr\u001b[39m(module, \u001b[33m\"\u001b[39m\u001b[33mforward_kwargs\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module.forward_kwargs)\n\u001b[32m   1174\u001b[39m         }\n\u001b[32m-> \u001b[39m\u001b[32m1175\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1176\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sentence_transformers\\models\\Transformer.py:259\u001b[39m, in \u001b[36mTransformer.forward\u001b[39m\u001b[34m(self, features, **kwargs)\u001b[39m\n\u001b[32m    237\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, features: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, torch.Tensor], **kwargs) -> \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, torch.Tensor]:\n\u001b[32m    238\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    239\u001b[39m \u001b[33;03m    Forward pass through the transformer model.\u001b[39;00m\n\u001b[32m    240\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    257\u001b[39m \u001b[33;03m            - 'all_layer_embeddings': If the model outputs hidden states, contains embeddings from all layers\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m259\u001b[39m     trans_features = {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[43mfeatures\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model_forward_params}\n\u001b[32m    261\u001b[39m     outputs = \u001b[38;5;28mself\u001b[39m.auto_model(**trans_features, **kwargs, return_dict=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    262\u001b[39m     token_embeddings = outputs[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pydantic\\main.py:1026\u001b[39m, in \u001b[36mBaseModel.__getattr__\u001b[39m\u001b[34m(self, item)\u001b[39m\n\u001b[32m   1023\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__getattribute__\u001b[39m(item)  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[32m   1024\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1025\u001b[39m     \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'ChatPromptValue' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\":\"What is deep Learning\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83957f32",
   "metadata": {},
   "source": [
    "### Create RAG Chain Alternative - Using LCEL (LangChain Expression Language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642d474f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5ad4df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"Use the following context to answer the question. \\nIf you don't know the answer based on the context, say you don't know.\\nProvide specific details from the context to support your answer.\\n\\nContext:\\n{context}\\n\\nQuestion: {question}\\n\\nAnswer:\"), additional_kwargs={})])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a custom prompt\n",
    "custom_prompt = ChatPromptTemplate.from_template(\"\"\"Use the following context to answer the question. \n",
    "If you don't know the answer based on the context, say you don't know.\n",
    "Provide specific details from the context to support your answer.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\")\n",
    "custom_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b68737",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'retriever' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m rag_chain_lcel=(\n\u001b[32m      2\u001b[39m     { \n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mcontext\u001b[39m\u001b[33m\"\u001b[39m:\u001b[43mretriever\u001b[49m | format_docs,\n\u001b[32m      4\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m: RunnablePassthrough()\n\u001b[32m      5\u001b[39m      }\n\u001b[32m      6\u001b[39m     | custom_prompt\n\u001b[32m      7\u001b[39m     | llm\n\u001b[32m      8\u001b[39m     | StrOutputParser()\n\u001b[32m      9\u001b[39m )\n\u001b[32m     11\u001b[39m rag_chain_lcel\n",
      "\u001b[31mNameError\u001b[39m: name 'retriever' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "rag_chain_lcel=(\n",
    "    { \n",
    "        \"context\":retriever | format_docs,\n",
    "        \"question\": RunnablePassthrough()\n",
    "     }\n",
    "    | custom_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain_lcel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e029c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=rag_chain_lcel.invoke(\"What is Deep Learning\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e41209",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'VectorStoreRetriever' object has no attribute 'get_relevant_documents'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mretriever\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_relevant_documents\u001b[49m(\u001b[33m\"\u001b[39m\u001b[33mWhat is Deep Learning\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pydantic\\main.py:1026\u001b[39m, in \u001b[36mBaseModel.__getattr__\u001b[39m\u001b[34m(self, item)\u001b[39m\n\u001b[32m   1023\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__getattribute__\u001b[39m(item)  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[32m   1024\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1025\u001b[39m     \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'VectorStoreRetriever' object has no attribute 'get_relevant_documents'"
     ]
    }
   ],
   "source": [
    "retriever.get_relevant_documents(\"What is Deep Learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a881718c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query using the LCEL approach - Fixed version\n",
    "def query_rag_lcel(question):\n",
    "    print(f\"Question: {question}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Method 1: Pass string directly (when using RunnablePassthrough)\n",
    "    answer = rag_chain_lcel.invoke(question)\n",
    "    print(f\"Answer: {answer}\")\n",
    "    \n",
    "    # Get source documents separately if needed\n",
    "    docs = retriever.get_relevant_documents(question)\n",
    "    print(\"\\nSource Documents:\")\n",
    "    for i, doc in enumerate(docs):\n",
    "        print(f\"\\n--- Source {i+1} ---\")\n",
    "        print(doc.page_content[:200] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d99092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing LCEL Chain:\n",
      "Question: What are the key concepts in reinforcement learning?\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'rag_chain_lcel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTesting LCEL Chain:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mquery_rag_lcel\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWhat are the key concepts in reinforcement learning?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mquery_rag_lcel\u001b[39m\u001b[34m(question)\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m50\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Method 1: Pass string directly (when using RunnablePassthrough)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m answer = \u001b[43mrag_chain_lcel\u001b[49m.invoke(question)\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAnswer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00manswer\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Get source documents separately if needed\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'rag_chain_lcel' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Testing LCEL Chain:\")\n",
    "query_rag_lcel(\"What are the key concepts in reinforcement learning?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1f0c2a",
   "metadata": {},
   "source": [
    "### Adding Groq llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9475b407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "def83c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getenv(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6042bf5c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_groq'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_groq\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatGroq\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchat_models\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m init_chat_model\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langchain_groq'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain.chat_models import init_chat_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a60f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(model=\"openai/gpt-oss-20b\", api_key=os.getenv(\"--\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ad2a5e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False, 'architecture': 'BertModel'})\n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1377a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
